A new study created in memory with name: no-name-0bab406e-0b5a-4ee2-b772-3ec9dddd2569
Im using: cuda
MyCustomModel.__init__ - uses: cuda
HelsinkiTranslator.__init__ - uses: cuda
Translator.__init__ - uses: cuda
FacebookLLM.__init__ - uses: cuda
Transformer.__init__ - uses: cuda
Transformer1.__init__ - uses: cuda
Transformer2.__init__ - uses: cuda
split_index = 48868

 original data size: 9356, clean: 9299

 original data size: 2347, clean: 2331


 epoch = 9294, total = 46470, warmup = 4647 


CombinedTrainer.__init__ - uses: cuda
{'loss': 9.6422, 'grad_norm': 30.69731330871582, 'learning_rate': 1.235628938988403e-05, 'epoch': 0.11}
{'loss': 9.1194, 'grad_norm': 51.72372055053711, 'learning_rate': 2.4824795333258428e-05, 'epoch': 0.22}
{'loss': 9.0411, 'grad_norm': 16.99323081970215, 'learning_rate': 3.729330127663283e-05, 'epoch': 0.32}
{'loss': 8.9212, 'grad_norm': 7.503341197967529, 'learning_rate': 4.976180722000723e-05, 'epoch': 0.43}
{'loss': 8.8258, 'grad_norm': 14.63638687133789, 'learning_rate': 5.746457311391408e-05, 'epoch': 0.54}
{'loss': 8.8638, 'grad_norm': 22.073421478271484, 'learning_rate': 5.607918356465026e-05, 'epoch': 0.65}
{'loss': 8.7912, 'grad_norm': 13.251922607421875, 'learning_rate': 5.469379401538644e-05, 'epoch': 0.75}
{'loss': 8.7, 'grad_norm': 12.944886207580566, 'learning_rate': 5.3309789855671876e-05, 'epoch': 0.86}
{'loss': 8.7743, 'grad_norm': 20.58636474609375, 'learning_rate': 5.192440030640806e-05, 'epoch': 0.97}
{'eval_loss': 8.770370483398438, 'eval_runtime': 2407.7995, 'eval_samples_per_second': 0.966, 'eval_steps_per_second': 0.966, 'epoch': 1.0}
{'loss': 8.8727, 'grad_norm': 14.54599666595459, 'learning_rate': 5.053901075714424e-05, 'epoch': 1.08}
{'loss': 8.7497, 'grad_norm': 18.80384635925293, 'learning_rate': 4.915362120788041e-05, 'epoch': 1.18}
{'loss': 8.8235, 'grad_norm': 14.963526725769043, 'learning_rate': 4.777100243771512e-05, 'epoch': 1.29}
{'loss': 8.6131, 'grad_norm': 20.526145935058594, 'learning_rate': 4.63856128884513e-05, 'epoch': 1.4}
{'loss': 8.5908, 'grad_norm': 13.22545337677002, 'learning_rate': 4.5001608728736734e-05, 'epoch': 1.51}
{'loss': 8.6502, 'grad_norm': 16.638580322265625, 'learning_rate': 4.361760456902218e-05, 'epoch': 1.61}
{'loss': 8.667, 'grad_norm': 19.867612838745117, 'learning_rate': 4.223221501975836e-05, 'epoch': 1.72}
{'loss': 8.8131, 'grad_norm': 7.269323348999023, 'learning_rate': 4.0848210860043794e-05, 'epoch': 1.83}
{'loss': 8.7797, 'grad_norm': 24.822589874267578, 'learning_rate': 3.9462821310779975e-05, 'epoch': 1.94}
{'eval_loss': 8.682347297668457, 'eval_runtime': 2447.9513, 'eval_samples_per_second': 0.95, 'eval_steps_per_second': 0.95, 'epoch': 2.0}
{'loss': 8.639, 'grad_norm': 13.850604057312012, 'learning_rate': 3.807743176151615e-05, 'epoch': 2.04}
{'loss': 8.6782, 'grad_norm': 10.113139152526855, 'learning_rate': 3.669204221225233e-05, 'epoch': 2.15}
{'loss': 8.6701, 'grad_norm': 22.248214721679688, 'learning_rate': 3.530665266298851e-05, 'epoch': 2.26}
{'loss': 8.7432, 'grad_norm': 11.213421821594238, 'learning_rate': 3.3921263113724685e-05, 'epoch': 2.37}
{'loss': 8.5338, 'grad_norm': 24.423124313354492, 'learning_rate': 3.2535873564460866e-05, 'epoch': 2.47}
{'loss': 8.544, 'grad_norm': 16.526145935058594, 'learning_rate': 3.115048401519704e-05, 'epoch': 2.58}
{'loss': 8.6367, 'grad_norm': 12.483989715576172, 'learning_rate': 2.9766479855482483e-05, 'epoch': 2.69}
{'loss': 8.533, 'grad_norm': 16.432575225830078, 'learning_rate': 2.8381090306218664e-05, 'epoch': 2.8}
{'loss': 8.6033, 'grad_norm': 10.42906665802002, 'learning_rate': 2.699570075695484e-05, 'epoch': 2.91}
{'eval_loss': 8.664868354797363, 'eval_runtime': 2486.3064, 'eval_samples_per_second': 0.936, 'eval_steps_per_second': 0.936, 'epoch': 3.0}
{'loss': 8.7751, 'grad_norm': 15.237533569335938, 'learning_rate': 2.5610311207691016e-05, 'epoch': 3.01}
{'loss': 8.7172, 'grad_norm': 28.04095458984375, 'learning_rate': 2.4224921658427194e-05, 'epoch': 3.12}
{'loss': 8.5154, 'grad_norm': 20.967199325561523, 'learning_rate': 2.283953210916337e-05, 'epoch': 3.23}
{'loss': 8.458, 'grad_norm': 28.22001838684082, 'learning_rate': 2.1455527949448814e-05, 'epoch': 3.34}
{'loss': 8.5445, 'grad_norm': 16.431575775146484, 'learning_rate': 2.0071523789734254e-05, 'epoch': 3.44}
{'loss': 8.7085, 'grad_norm': 18.289470672607422, 'learning_rate': 1.868613424047043e-05, 'epoch': 3.55}
{'loss': 8.4557, 'grad_norm': 18.22226905822754, 'learning_rate': 1.7302130080755878e-05, 'epoch': 3.66}
{'loss': 8.6334, 'grad_norm': 11.276032447814941, 'learning_rate': 1.5918125921041317e-05, 'epoch': 3.77}
{'loss': 8.5052, 'grad_norm': 10.762508392333984, 'learning_rate': 1.4532736371777496e-05, 'epoch': 3.87}
{'loss': 8.6264, 'grad_norm': 22.148643493652344, 'learning_rate': 1.3147346822513672e-05, 'epoch': 3.98}
Trial 0 failed with parameters: {'lr': 5.7941147118860835e-05, 'weight_decay': 6.80970791918829e-05} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/home/ddn1/Documents/GitHub/He_LLM/utilty/BestHyper.py", line 35, in objective
    eval_loss = self.train_and_evaluate(
  File "/home/ddn1/Documents/GitHub/He_LLM/models/custom_model.py", line 212, in train_and_evaluate
    batch_size=batch_size,
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py", line 1948, in train
    return inner_training_loop(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py", line 2289, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/trainer.py", line 3328, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/ddn1/Documents/GitHub/He_LLM/custom_trainers/combined_model_trainer.py", line 56, in compute_loss
    outputs = model(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 820, in forward
    return model_forward(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 808, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/ddn1/Documents/GitHub/He_LLM/models/custom_model.py", line 103, in forward
  File "/home/ddn1/Documents/GitHub/He_LLM/translation/translator.py", line 75, in get_output_by_using_dummy
  File "/home/ddn1/Documents/GitHub/He_LLM/translation/translator.py", line 129, in generate_sentence_from_outputs
    else:
  File "/home/ddn1/Documents/GitHub/He_LLM/translation/translator.py", line 168, in process_outputs
    decoder_input_ids=decoder_input_ids,
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py", line 1399, in forward
    outputs = self.model(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py", line 1194, in forward
    decoder_outputs = self.decoder(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py", line 994, in forward
    layer_outputs = decoder_layer(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py", line 404, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py", line 186, in forward
    value_states = self._shape(self.v_proj(hidden_states), -1, bsz)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ddn1/anaconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
Trial 0 failed with value None.
{'eval_loss': 8.637125968933105, 'eval_runtime': 2529.0026, 'eval_samples_per_second': 0.92, 'eval_steps_per_second': 0.92, 'epoch': 4.0}
{'loss': 8.4463, 'grad_norm': 24.22269058227539, 'learning_rate': 1.1763342662799115e-05, 'epoch': 4.09}
